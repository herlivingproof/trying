{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korakoe/StyleTTS2/blob/main/Colab/StyleTTS2_Finetune_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install packages and download models"
      ],
      "metadata": {
        "id": "yLqBa4uYPrqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG64C8KKDzh5",
        "outputId": "72a99b46-bf5a-4b27-9a8b-28549704f2a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soundfile==0.10.3.post1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq1lW-qZdP9P",
        "outputId": "a1475408-8934-448a-c8cb-5591a9e68b70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting soundfile==0.10.3.post1\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile==0.10.3.post1) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1) (2.21)\n",
            "Installing collected packages: soundfile\n",
            "  Attempting uninstall: soundfile\n",
            "    Found existing installation: soundfile 0.12.1\n",
            "    Uninstalling soundfile-0.12.1:\n",
            "      Successfully uninstalled soundfile-0.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.10.1 requires soundfile>=0.12.1, but you have soundfile 0.10.3.post1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed soundfile-0.10.3.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git clone https://github.com/yl4579/StyleTTS2.git\n",
        "cd StyleTTS2\n",
        "pip install soundfile==0.10.3.post1 torchaudio munch torch pydub pyyaml librosa nltk matplotlib accelerate transformers phonemizer einops einops-exts tqdm typing-extensions git+https://github.com/resemble-ai/monotonic_align.git\n",
        "sudo apt-get install espeak-ng\n",
        "git-lfs clone https://huggingface.co/yl4579/StyleTTS2-LibriTTS\n",
        "mv StyleTTS2-LibriTTS/Models ."
      ],
      "metadata": {
        "id": "H72WF06ZPrTF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "7f0a0875-aaa1-4a66-c741-30969dff02d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'StyleTTS2' already exists and is not an empty directory.\n",
            "Collecting git+https://github.com/resemble-ai/monotonic_align.git\n",
            "  Cloning https://github.com/resemble-ai/monotonic_align.git to /tmp/pip-req-build-ny2awo8n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/resemble-ai/monotonic_align.git /tmp/pip-req-build-ny2awo8n\n",
            "  Resolved https://github.com/resemble-ai/monotonic_align.git to commit 78b985be210a03d08bc3acc01c4df0442105366f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6f3a01f3513c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'git clone https://github.com/yl4579/StyleTTS2.git\\ncd StyleTTS2\\npip install soundfile==0.10.3.post1 torchaudio munch torch pydub pyyaml librosa nltk matplotlib accelerate transformers phonemizer einops einops-exts tqdm typing-extensions git+https://github.com/resemble-ai/monotonic_align.git\\nsudo apt-get install espeak-ng\\ngit-lfs clone https://huggingface.co/yl4579/StyleTTS2-LibriTTS\\nmv StyleTTS2-LibriTTS/Models .\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'git clone https://github.com/yl4579/StyleTTS2.git\ncd StyleTTS2\npip install soundfile==0.10.3.post1 torchaudio munch torch pydub pyyaml librosa nltk matplotlib accelerate transformers phonemizer einops einops-exts tqdm typing-extensions git+https://github.com/resemble-ai/monotonic_align.git\nsudo apt-get install espeak-ng\ngit-lfs clone https://huggingface.co/yl4579/StyleTTS2-LibriTTS\nmv StyleTTS2-LibriTTS/Models .\n' died with <Signals.SIGTERM: 15>."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download dataset (LJSpeech, 200 samples, ~15 minutes of data)\n",
        "\n",
        "You can definitely do it with fewer samples. This is just a proof of concept with 200 smaples."
      ],
      "metadata": {
        "id": "G398sL8wPzTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd StyleTTS2\n",
        "!rm -rf Data"
      ],
      "metadata": {
        "id": "kJuQUBrEPy5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13f363d-29ed-432b-a308-0bb52cf3889f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/StyleTTS2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1vqz26D3yn7OXS2vbfYxfSnpLS6m6tOFP\n",
        "!unzip Data.zip"
      ],
      "metadata": {
        "id": "mDXW8ZZePuSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Unphonemized (only do if you're using a text based ljspeech dataset)"
      ],
      "metadata": {
        "id": "3m93S00hq7pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convert\n",
        "path_to_wavs_txt = \"/content/drive/Othercomputers/My Laptop/Voice Clones/Me/wavs.txt\" # @param {type:\"string\"}\n",
        "save_to_path = \"/content/drive/Othercomputers/My Laptop/Voice Clones/Me/Train_list.txt\" # @param {type:\"string\"}\n",
        "import phonemizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "with open(path_to_wavs_txt, 'r', encoding=\"utf8\") as fh:\n",
        "    lines = fh.readlines()\n",
        "\n",
        "final = []\n",
        "for line in tqdm(lines):\n",
        "    data = line.replace(\"\\n\", \"\").split(\"|\")\n",
        "    data[1] = phonemizer.phonemize(data[1], backend=\"espeak\", with_stress=True, preserve_punctuation=True, njobs=4, strip=True)\n",
        "    if len(data) < 3:\n",
        "        data.append(0)\n",
        "\n",
        "    final.append(f\"{data[0]}|{data[1]}|{data[2]}\")\n",
        "\n",
        "with open(save_to_path, 'w', encoding=\"utf8\") as fh:\n",
        "    final = \"\\n\".join(final)\n",
        "    fh.write(final)"
      ],
      "metadata": {
        "id": "Ql8NXtQGrSDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "fe28f7b6-6f0f-440b-cdd3-d565653fce89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 2/140 [00:00<00:10, 13.40it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "  3%|▎         | 4/140 [00:00<00:09, 14.05it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "  6%|▌         | 8/140 [00:00<00:09, 14.17it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "  7%|▋         | 10/140 [00:00<00:08, 14.74it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "  9%|▊         | 12/140 [00:00<00:08, 14.37it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 10%|█         | 14/140 [00:01<00:10, 11.90it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 13%|█▎        | 18/140 [00:01<00:09, 12.25it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 14%|█▍        | 20/140 [00:01<00:09, 12.96it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 16%|█▌        | 22/140 [00:01<00:08, 13.11it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 17%|█▋        | 24/140 [00:01<00:08, 13.02it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 19%|█▊        | 26/140 [00:01<00:08, 13.14it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 20%|██        | 28/140 [00:02<00:08, 12.48it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 21%|██▏       | 30/140 [00:02<00:08, 13.01it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 23%|██▎       | 32/140 [00:02<00:08, 13.42it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 26%|██▌       | 36/140 [00:02<00:07, 14.36it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 27%|██▋       | 38/140 [00:02<00:07, 14.02it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 29%|██▊       | 40/140 [00:02<00:07, 14.28it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 31%|███▏      | 44/140 [00:03<00:06, 15.01it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 37%|███▋      | 52/140 [00:03<00:05, 16.08it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 39%|███▊      | 54/140 [00:03<00:05, 15.49it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 40%|████      | 56/140 [00:04<00:06, 13.98it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 43%|████▎     | 60/140 [00:04<00:05, 14.50it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 44%|████▍     | 62/140 [00:04<00:05, 13.85it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 46%|████▌     | 64/140 [00:04<00:05, 13.81it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 47%|████▋     | 66/140 [00:04<00:05, 13.79it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 50%|█████     | 70/140 [00:05<00:05, 13.45it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 51%|█████▏    | 72/140 [00:05<00:05, 13.53it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 53%|█████▎    | 74/140 [00:05<00:05, 13.11it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 54%|█████▍    | 76/140 [00:05<00:05, 11.71it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 56%|█████▌    | 78/140 [00:06<00:07,  8.42it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 56%|█████▋    | 79/140 [00:06<00:07,  8.18it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 58%|█████▊    | 81/140 [00:06<00:06,  8.95it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 59%|█████▉    | 83/140 [00:06<00:05,  9.59it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 61%|██████    | 85/140 [00:06<00:05,  9.90it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 64%|██████▎   | 89/140 [00:07<00:05,  9.27it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 65%|██████▌   | 91/140 [00:07<00:04, 10.04it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 66%|██████▋   | 93/140 [00:07<00:04, 10.27it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 70%|███████   | 98/140 [00:08<00:04,  9.70it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 71%|███████▏  | 100/140 [00:08<00:04,  9.18it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 74%|███████▎  | 103/140 [00:08<00:04,  9.01it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 76%|███████▌  | 106/140 [00:08<00:03,  9.18it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 78%|███████▊  | 109/140 [00:09<00:03,  9.91it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 79%|███████▉  | 111/140 [00:09<00:03,  9.25it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 80%|████████  | 112/140 [00:09<00:03,  9.02it/s]WARNING:phonemizer:words count mismatch on 300.0% of the lines (3/1)\n",
            " 81%|████████  | 113/140 [00:09<00:02,  9.18it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 82%|████████▏ | 115/140 [00:09<00:02,  9.43it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 84%|████████▎ | 117/140 [00:10<00:02, 10.07it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 85%|████████▌ | 119/140 [00:10<00:01, 10.89it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 86%|████████▋ | 121/140 [00:10<00:01, 10.32it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 88%|████████▊ | 123/140 [00:10<00:01, 10.64it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 89%|████████▉ | 125/140 [00:10<00:01,  9.99it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 91%|█████████ | 127/140 [00:11<00:01,  8.87it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 93%|█████████▎| 130/140 [00:11<00:01,  8.91it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 94%|█████████▎| 131/140 [00:11<00:01,  8.99it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 96%|█████████▌| 134/140 [00:11<00:00,  9.31it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 98%|█████████▊| 137/140 [00:12<00:00,  9.48it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 99%|█████████▊| 138/140 [00:12<00:00,  9.20it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "100%|██████████| 140/140 [00:12<00:00, 11.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Change the finetuning config\n",
        "\n",
        "Depending on the GPU you got, you may want to change the bacth size, max audio length, epiochs and so on."
      ],
      "metadata": {
        "id": "_AlBQREWU8ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = \"Configs/config_ft.yml\"\n",
        "\n",
        "import yaml\n",
        "config = yaml.safe_load(open(config_path))"
      ],
      "metadata": {
        "id": "7uEITi0hU4I2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Training Config\n",
        "dataset_path = \"/content/drive/Othercomputers/My Laptop/Voice Clones/Me/\" # @param {type:\"string\"}\n",
        "train_list_path = \"/content/drive/Othercomputers/My Laptop/Voice Clones/Me/Train_list.txt\" # @param {type:\"string\"}\n",
        "val_list_path = \"/content/drive/Othercomputers/My Laptop/Voice Clones/Me/Val_list.txt\" # @param {type:\"string\"}\n",
        "OOD_text_path = \"/content/drive/Othercomputers/My Laptop/Voice Clones/Me/OOD_texts.txt\" # @param {type:\"string\"}\n",
        "log_dir = \"/content/drive/Othercomputers/My Laptop/Voice Clones/Me/\" # @param {type:\"string\"}\n",
        "\n",
        "batch_size = 2 # @param {type:\"integer\"}\n",
        "save_every = 5 # @param {type:\"integer\"}\n",
        "log_every = 1 # @param {type:\"integer\"}\n",
        "max_len = 100 # @param {type:\"integer\"}\n",
        "epochs = 100 # @param {type:\"integer\"}\n",
        "learning_rate = 0.0001 # @param {type:\"number\"}\n",
        "joint_epoch = 110 # @param {type:\"integer\"}\n",
        "config['data_params']['root_path'] = dataset_path\n",
        "config['log_dir'] = log_dir\n",
        "config['data_params']['train_data'] = train_list_path\n",
        "config['data_params']['val_data'] = val_list_path\n",
        "config['data_params']['OOD_data'] = OOD_text_path\n",
        "\n",
        "config['batch_size'] = batch_size # not enough RAM\n",
        "config['max_len'] = max_len # not enough RAM\n",
        "config['epochs'] = epochs\n",
        "config['save_freq'] = save_every\n",
        "config['log_interval'] = log_every\n",
        "config['loss_params']['joint_epoch'] = joint_epoch # we do not do SLM adversarial training due to not enough RAM\n",
        "config['optimizer_params']['lr'] = learning_rate\n",
        "\n",
        "with open(config_path, 'w') as outfile:\n",
        "  yaml.dump(config, outfile, default_flow_style=True)"
      ],
      "metadata": {
        "id": "TPTRgOKSVT4K",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start finetuning\n"
      ],
      "metadata": {
        "id": "uUuB_19NWj2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "fin = os.path.join(log_dir, \"/tensorboard\")\n",
        "\n",
        "%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir $fin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "U5RYNTNWf4S_",
        "outputId": "af60339a-19c1-458c-cff5-f35b8ccb0995"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "2023-11-26 07:40:04.459257: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
              "2023-11-26 07:40:04.459342: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
              "2023-11-26 07:40:04.459380: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
              "2023-11-26 07:40:04.470488: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
              "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
              "2023-11-26 07:40:05.889188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
              "2023-11-26 07:40:07.881805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
              "2023-11-26 07:40:07.922214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
              "2023-11-26 07:40:07.922571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
              "\n",
              "NOTE: Using experimental fast data loading logic. To disable, pass\n",
              "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
              "    https://github.com/tensorflow/tensorboard/issues/4784\n",
              "\n",
              "Address already in use\n",
              "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_finetune.py --config_path ./Configs/config_ft.yml"
      ],
      "metadata": {
        "id": "HZVAD5GKWm-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e45d35-b2a3-4ead-a5e8-b0116be57ead"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-26 07:34:25.568776: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-26 07:34:25.568839: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-26 07:34:25.568876: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-26 07:34:25.580724: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-26 07:34:27.243432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Some weights of the model checkpoint at microsoft/wavlm-base-plus were not used when initializing WavLMModel: ['encoder.pos_conv_embed.conv.weight_v', 'encoder.pos_conv_embed.conv.weight_g']\n",
            "- This IS expected if you are initializing WavLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing WavLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of WavLMModel were not initialized from the model checkpoint at microsoft/wavlm-base-plus and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "bert loaded\n",
            "bert_encoder loaded\n",
            "predictor loaded\n",
            "decoder loaded\n",
            "text_encoder loaded\n",
            "predictor_encoder loaded\n",
            "style_encoder loaded\n",
            "diffusion loaded\n",
            "text_aligner loaded\n",
            "pitch_extractor loaded\n",
            "mpd loaded\n",
            "msd loaded\n",
            "wd loaded\n",
            "BERT AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    base_momentum: 0.85\n",
            "    betas: (0.9, 0.99)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-09\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    initial_lr: 1e-05\n",
            "    lr: 1e-05\n",
            "    max_lr: 2e-05\n",
            "    max_momentum: 0.95\n",
            "    maximize: False\n",
            "    min_lr: 0\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "decoder AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    base_momentum: 0.85\n",
            "    betas: (0.0, 0.99)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-09\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0001\n",
            "    max_lr: 0.0002\n",
            "    max_momentum: 0.95\n",
            "    maximize: False\n",
            "    min_lr: 0\n",
            "    weight_decay: 0.0001\n",
            ")\n",
            "wavs/0_7.wav 48000\n",
            "wavs/11_17.wav 48000\n",
            "wavs/4_0.wav 48000\n",
            "wavs/14_1.wav 48000\n",
            "wavs/2_0.wav 48000\n",
            "wavs/0_6.wav 48000\n",
            "wavs/16_10.wav 48000\n",
            "wavs/16_11.wav 48000\n",
            "wavs/0_16.wav 48000\n",
            "wavs/14_3.wav 48000\n",
            "wavs/11_6.wav 48000\n",
            "wavs/2_3.wav 48000\n",
            "wavs/19_0.wav 48000\n",
            "wavs/5_12.wav 44100\n",
            "wavs/11_15.wav 48000\n",
            "wavs/16_3.wav 48000\n",
            "wavs/5_1.wav 44100\n",
            "wavs/2_2.wav 48000\n",
            "wavs/0_6.wav 48000\n",
            "wavs/11_2.wav 48000\n",
            "Epoch [1/100], Step [1/70], Loss: 0.45394, Disc Loss: 4.03568, Dur Loss: 1.32130, CE Loss: 0.08290, Norm Loss: 0.58985, F0 Loss: 2.80569, LM Loss: 1.45223, Gen Loss: 5.07492, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.73398, Mono Loss: 0.03208\n",
            "Time elasped: 8.421083211898804\n",
            "wavs/2_3.wav 48000\n",
            "wavs/11_3.wav 48000\n",
            "wavs/5_3.wav 44100\n",
            "wavs/11_5.wav 48000\n",
            "Epoch [1/100], Step [2/70], Loss: 0.56136, Disc Loss: 3.78327, Dur Loss: 1.39326, CE Loss: 0.09012, Norm Loss: 1.00284, F0 Loss: 2.26246, LM Loss: 1.74118, Gen Loss: 6.28474, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.75889, Mono Loss: 0.03138\n",
            "Time elasped: 11.365583419799805\n",
            "wavs/11_16.wav 48000\n",
            "wavs/0_10.wav 48000\n",
            "wavs/0_16.wav 48000\n",
            "wavs/0_9.wav 48000\n",
            "Epoch [1/100], Step [3/70], Loss: 0.40145, Disc Loss: 3.84488, Dur Loss: 1.22274, CE Loss: 0.10048, Norm Loss: 0.56685, F0 Loss: 1.73273, LM Loss: 1.41922, Gen Loss: 6.35188, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.99984, Mono Loss: 0.03412\n",
            "Time elasped: 13.819016933441162\n",
            "wavs/12_8.wav 48000\n",
            "wavs/5_8.wav 44100\n",
            "wavs/6_2.wav 48000\n",
            "wavs/10_0.wav 48000\n",
            "Epoch [1/100], Step [4/70], Loss: 0.37254, Disc Loss: 4.45526, Dur Loss: 0.90516, CE Loss: 0.04149, Norm Loss: 0.51427, F0 Loss: 1.63595, LM Loss: 1.28068, Gen Loss: 8.07911, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.70933, Mono Loss: 0.04181\n",
            "Time elasped: 16.198867797851562\n",
            "wavs/0_13.wav 48000\n",
            "wavs/0_0.wav 48000\n",
            "wavs/16_20.wav 48000\n",
            "wavs/16_5.wav 48000\n",
            "Epoch [1/100], Step [5/70], Loss: 0.47576, Disc Loss: 4.01447, Dur Loss: 1.08125, CE Loss: 0.05970, Norm Loss: 1.34659, F0 Loss: 3.14426, LM Loss: 2.13739, Gen Loss: 7.23613, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.92905, Mono Loss: 0.03578\n",
            "Time elasped: 19.074614763259888\n",
            "wavs/11_13.wav 48000\n",
            "wavs/12_5.wav 48000\n",
            "wavs/12_6.wav 48000\n",
            "wavs/11_3.wav 48000\n",
            "Epoch [1/100], Step [6/70], Loss: 0.39822, Disc Loss: 3.87485, Dur Loss: 0.58363, CE Loss: 0.02531, Norm Loss: 0.58268, F0 Loss: 2.29788, LM Loss: 1.61334, Gen Loss: 8.29930, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.68296, Mono Loss: 0.02696\n",
            "Time elasped: 21.944901943206787\n",
            "wavs/19_2.wav 48000\n",
            "wavs/12_6.wav 48000\n",
            "wavs/5_5.wav 44100\n",
            "wavs/11_1.wav 48000\n",
            "Epoch [1/100], Step [7/70], Loss: 0.35847, Disc Loss: 3.87300, Dur Loss: 0.75159, CE Loss: 0.03660, Norm Loss: 0.53981, F0 Loss: 1.25229, LM Loss: 1.74713, Gen Loss: 5.73929, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.67884, Mono Loss: 0.02592\n",
            "Time elasped: 25.40743136405945\n",
            "wavs/0_1.wav 48000\n",
            "wavs/14_1.wav 48000\n",
            "wavs/5_9.wav 44100\n",
            "wavs/16_23.wav 48000\n",
            "Epoch [1/100], Step [8/70], Loss: 0.42785, Disc Loss: 3.91300, Dur Loss: 1.05445, CE Loss: 0.05395, Norm Loss: 0.57878, F0 Loss: 1.31784, LM Loss: 1.46400, Gen Loss: 5.31622, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.90630, Mono Loss: 0.04709\n",
            "Time elasped: 28.023162364959717\n",
            "wavs/0_11.wav 48000\n",
            "wavs/16_11.wav 48000\n",
            "wavs/5_11.wav 44100\n",
            "wavs/19_5.wav 48000\n",
            "Epoch [1/100], Step [9/70], Loss: 0.37500, Disc Loss: 3.97018, Dur Loss: 0.80772, CE Loss: 0.03907, Norm Loss: 0.90519, F0 Loss: 2.18812, LM Loss: 1.42716, Gen Loss: 5.95618, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.49105, Mono Loss: 0.03043\n",
            "Time elasped: 30.60476589202881\n",
            "wavs/15_6.wav 48000\n",
            "wavs/3_1.wav 48000\n",
            "wavs/11_15.wav 48000\n",
            "wavs/5_14.wav 44100\n",
            "Epoch [1/100], Step [10/70], Loss: 0.47595, Disc Loss: 4.00597, Dur Loss: 3.03876, CE Loss: 0.20300, Norm Loss: 0.74276, F0 Loss: 1.81704, LM Loss: 1.47527, Gen Loss: 5.41840, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 1.30214, Mono Loss: 0.02987\n",
            "Time elasped: 33.289719343185425\n",
            "wavs/7_0.wav 48000\n",
            "wavs/16_15.wav 48000\n",
            "wavs/14_0.wav 48000\n",
            "wavs/5_6.wav 44100\n",
            "Epoch [1/100], Step [11/70], Loss: 0.41063, Disc Loss: 3.87075, Dur Loss: 0.71157, CE Loss: 0.04101, Norm Loss: 0.46109, F0 Loss: 2.05829, LM Loss: 1.75410, Gen Loss: 7.67995, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.51219, Mono Loss: 0.03820\n",
            "Time elasped: 35.7265191078186\n",
            "wavs/5_2.wav 44100\n",
            "wavs/0_9.wav 48000\n",
            "wavs/7_1.wav 48000\n",
            "wavs/18_2.wav 48000\n",
            "Epoch [1/100], Step [12/70], Loss: 0.31871, Disc Loss: 4.03800, Dur Loss: 0.68142, CE Loss: 0.03448, Norm Loss: 0.64407, F0 Loss: 2.27243, LM Loss: 1.38932, Gen Loss: 7.46273, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.60976, Mono Loss: 0.02498\n",
            "Time elasped: 38.78001832962036\n",
            "wavs/15_7.wav 48000\n",
            "wavs/16_19.wav 48000\n",
            "wavs/16_3.wav 48000\n",
            "wavs/15_8.wav 48000\n",
            "Epoch [1/100], Step [13/70], Loss: 0.32860, Disc Loss: 3.96213, Dur Loss: 0.54854, CE Loss: 0.02689, Norm Loss: 0.53684, F0 Loss: 3.08860, LM Loss: 1.42296, Gen Loss: 6.66820, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.40013, Mono Loss: 0.02557\n",
            "Time elasped: 42.038501262664795\n",
            "wavs/6_0.wav 48000\n",
            "wavs/2_3.wav 48000\n",
            "wavs/19_4.wav 48000\n",
            "wavs/2_2.wav 48000\n",
            "Epoch [1/100], Step [14/70], Loss: 0.42334, Disc Loss: 3.90190, Dur Loss: 0.94022, CE Loss: 0.06544, Norm Loss: 0.56225, F0 Loss: 1.79704, LM Loss: 1.52780, Gen Loss: 5.90142, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.93323, Mono Loss: 0.04034\n",
            "Time elasped: 44.84728646278381\n",
            "wavs/12_3.wav 48000\n",
            "wavs/12_1.wav 48000\n",
            "wavs/12_0.wav 48000\n",
            "wavs/19_0.wav 48000\n",
            "Epoch [1/100], Step [15/70], Loss: 0.49745, Disc Loss: 3.88014, Dur Loss: 1.18268, CE Loss: 0.06237, Norm Loss: 0.60191, F0 Loss: 1.84903, LM Loss: 1.69377, Gen Loss: 5.92911, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 1.04639, Mono Loss: 0.03765\n",
            "Time elasped: 47.784398794174194\n",
            "wavs/12_4.wav 48000\n",
            "wavs/16_12.wav 48000\n",
            "wavs/5_15.wav 44100\n",
            "wavs/11_6.wav 48000\n",
            "Epoch [1/100], Step [16/70], Loss: 0.35081, Disc Loss: 4.15977, Dur Loss: 0.83639, CE Loss: 0.04214, Norm Loss: 0.61471, F0 Loss: 1.47369, LM Loss: 1.48150, Gen Loss: 7.59717, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 0.82912, Mono Loss: 0.03041\n",
            "Time elasped: 51.349501848220825\n",
            "wavs/11_0.wav 48000\n",
            "wavs/11_12.wav 48000\n",
            "wavs/1_2.wav 48000\n",
            "wavs/19_4.wav 48000\n",
            "Epoch [1/100], Step [17/70], Loss: 0.64573, Disc Loss: 3.81299, Dur Loss: 1.12898, CE Loss: 0.20284, Norm Loss: 1.87814, F0 Loss: 4.93146, LM Loss: 2.20797, Gen Loss: 5.93179, Sty Loss: 0.00000, Diff Loss: 0.00000, DiscLM Loss: 0.00000, GenLM Loss: 0.00000, SLoss: 0.00000, S2S Loss: 1.11573, Mono Loss: 0.04286\n",
            "Time elasped: 54.095335245132446\n",
            "wavs/11_6.wav 48000\n",
            "wavs/0_5.wav 48000\n",
            "wavs/16_19.wav 48000\n",
            "wavs/8_1.wav 48000\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the model quality\n",
        "\n",
        "Note that this mainly serves as a proof of concept due to RAM limitation of free Colab instances. A lot of settings are suboptimal. In the future when DDP works for train_second.py, we will also add mixed precision finetuning to save time and RAM. You can also add SLM adversarial training run if you have paid Colab services (such as A100 with 40G of RAM)."
      ],
      "metadata": {
        "id": "I0_7wsGkXGfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "OPLphjbncE7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "# load packages\n",
        "import time\n",
        "import random\n",
        "import yaml\n",
        "from munch import Munch\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import librosa\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from models import *\n",
        "from utils import *\n",
        "from text_utils import TextCleaner\n",
        "textclenaer = TextCleaner()\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "to_mel = torchaudio.transforms.MelSpectrogram(\n",
        "    n_mels=80, n_fft=2048, win_length=1200, hop_length=300)\n",
        "mean, std = -4, 4\n",
        "\n",
        "def length_to_mask(lengths):\n",
        "    mask = torch.arange(lengths.max()).unsqueeze(0).expand(lengths.shape[0], -1).type_as(lengths)\n",
        "    mask = torch.gt(mask+1, lengths.unsqueeze(1))\n",
        "    return mask\n",
        "\n",
        "def preprocess(wave):\n",
        "    wave_tensor = torch.from_numpy(wave).float()\n",
        "    mel_tensor = to_mel(wave_tensor)\n",
        "    mel_tensor = (torch.log(1e-5 + mel_tensor.unsqueeze(0)) - mean) / std\n",
        "    return mel_tensor\n",
        "\n",
        "def compute_style(path):\n",
        "    wave, sr = librosa.load(path, sr=24000)\n",
        "    audio, index = librosa.effects.trim(wave, top_db=30)\n",
        "    if sr != 24000:\n",
        "        audio = librosa.resample(audio, sr, 24000)\n",
        "    mel_tensor = preprocess(audio).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        ref_s = model.style_encoder(mel_tensor.unsqueeze(1))\n",
        "        ref_p = model.predictor_encoder(mel_tensor.unsqueeze(1))\n",
        "\n",
        "    return torch.cat([ref_s, ref_p], dim=1)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# load phonemizer\n",
        "import phonemizer\n",
        "global_phonemizer = phonemizer.backend.EspeakBackend(language='en-us', preserve_punctuation=True,  with_stress=True)\n",
        "\n",
        "config = yaml.safe_load(open(\"Models/LJSpeech/config_ft.yml\"))\n",
        "\n",
        "# load pretrained ASR model\n",
        "ASR_config = config.get('ASR_config', False)\n",
        "ASR_path = config.get('ASR_path', False)\n",
        "text_aligner = load_ASR_models(ASR_path, ASR_config)\n",
        "\n",
        "# load pretrained F0 model\n",
        "F0_path = config.get('F0_path', False)\n",
        "pitch_extractor = load_F0_models(F0_path)\n",
        "\n",
        "# load BERT model\n",
        "from Utils.PLBERT.util import load_plbert\n",
        "BERT_path = config.get('PLBERT_dir', False)\n",
        "plbert = load_plbert(BERT_path)\n",
        "\n",
        "model_params = recursive_munch(config['model_params'])\n",
        "model = build_model(model_params, text_aligner, pitch_extractor, plbert)\n",
        "_ = [model[key].eval() for key in model]\n",
        "_ = [model[key].to(device) for key in model]"
      ],
      "metadata": {
        "id": "jIIAoDACXJL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [f for f in os.listdir(\"Models/LJSpeech/\") if f.endswith('.pth')]\n",
        "sorted_files = sorted(files, key=lambda x: int(x.split('_')[-1].split('.')[0]))"
      ],
      "metadata": {
        "id": "eKXRAyyzcMpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_whole = torch.load(\"Models/LJSpeech/\" + sorted_files[-1], map_location='cpu')\n",
        "params = params_whole['net']"
      ],
      "metadata": {
        "id": "ULuU9-VDb9Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in model:\n",
        "    if key in params:\n",
        "        print('%s loaded' % key)\n",
        "        try:\n",
        "            model[key].load_state_dict(params[key])\n",
        "        except:\n",
        "            from collections import OrderedDict\n",
        "            state_dict = params[key]\n",
        "            new_state_dict = OrderedDict()\n",
        "            for k, v in state_dict.items():\n",
        "                name = k[7:] # remove `module.`\n",
        "                new_state_dict[name] = v\n",
        "            # load params\n",
        "            model[key].load_state_dict(new_state_dict, strict=False)\n",
        "#             except:\n",
        "#                 _load(params[key], model[key])\n",
        "_ = [model[key].eval() for key in model]"
      ],
      "metadata": {
        "id": "J-U29yIYc2ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Modules.diffusion.sampler import DiffusionSampler, ADPM2Sampler, KarrasSchedule"
      ],
      "metadata": {
        "id": "jrPQ_Yrwc3n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = DiffusionSampler(\n",
        "    model.diffusion.diffusion,\n",
        "    sampler=ADPM2Sampler(),\n",
        "    sigma_schedule=KarrasSchedule(sigma_min=0.0001, sigma_max=3.0, rho=9.0), # empirical parameters\n",
        "    clamp=False\n",
        ")"
      ],
      "metadata": {
        "id": "n2CWYNoqc455"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(text, ref_s, alpha = 0.3, beta = 0.7, diffusion_steps=5, embedding_scale=1):\n",
        "    text = text.strip()\n",
        "    ps = global_phonemizer.phonemize([text])\n",
        "    ps = word_tokenize(ps[0])\n",
        "    ps = ' '.join(ps)\n",
        "    tokens = textclenaer(ps)\n",
        "    tokens.insert(0, 0)\n",
        "    tokens = torch.LongTensor(tokens).to(device).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_lengths = torch.LongTensor([tokens.shape[-1]]).to(device)\n",
        "        text_mask = length_to_mask(input_lengths).to(device)\n",
        "\n",
        "        t_en = model.text_encoder(tokens, input_lengths, text_mask)\n",
        "        bert_dur = model.bert(tokens, attention_mask=(~text_mask).int())\n",
        "        d_en = model.bert_encoder(bert_dur).transpose(-1, -2)\n",
        "\n",
        "        s_pred = sampler(noise = torch.randn((1, 256)).unsqueeze(1).to(device),\n",
        "                                          embedding=bert_dur,\n",
        "                                          embedding_scale=embedding_scale,\n",
        "                                            features=ref_s, # reference from the same speaker as the embedding\n",
        "                                             num_steps=diffusion_steps).squeeze(1)\n",
        "\n",
        "\n",
        "        s = s_pred[:, 128:]\n",
        "        ref = s_pred[:, :128]\n",
        "\n",
        "        ref = alpha * ref + (1 - alpha)  * ref_s[:, :128]\n",
        "        s = beta * s + (1 - beta)  * ref_s[:, 128:]\n",
        "\n",
        "        d = model.predictor.text_encoder(d_en,\n",
        "                                         s, input_lengths, text_mask)\n",
        "\n",
        "        x, _ = model.predictor.lstm(d)\n",
        "        duration = model.predictor.duration_proj(x)\n",
        "\n",
        "        duration = torch.sigmoid(duration).sum(axis=-1)\n",
        "        pred_dur = torch.round(duration.squeeze()).clamp(min=1)\n",
        "\n",
        "        pred_aln_trg = torch.zeros(input_lengths, int(pred_dur.sum().data))\n",
        "        c_frame = 0\n",
        "        for i in range(pred_aln_trg.size(0)):\n",
        "            pred_aln_trg[i, c_frame:c_frame + int(pred_dur[i].data)] = 1\n",
        "            c_frame += int(pred_dur[i].data)\n",
        "\n",
        "        # encode prosody\n",
        "        en = (d.transpose(-1, -2) @ pred_aln_trg.unsqueeze(0).to(device))\n",
        "        if model_params.decoder.type == \"hifigan\":\n",
        "            asr_new = torch.zeros_like(en)\n",
        "            asr_new[:, :, 0] = en[:, :, 0]\n",
        "            asr_new[:, :, 1:] = en[:, :, 0:-1]\n",
        "            en = asr_new\n",
        "\n",
        "        F0_pred, N_pred = model.predictor.F0Ntrain(en, s)\n",
        "\n",
        "        asr = (t_en @ pred_aln_trg.unsqueeze(0).to(device))\n",
        "        if model_params.decoder.type == \"hifigan\":\n",
        "            asr_new = torch.zeros_like(asr)\n",
        "            asr_new[:, :, 0] = asr[:, :, 0]\n",
        "            asr_new[:, :, 1:] = asr[:, :, 0:-1]\n",
        "            asr = asr_new\n",
        "\n",
        "        out = model.decoder(asr,\n",
        "                                F0_pred, N_pred, ref.squeeze().unsqueeze(0))\n",
        "\n",
        "\n",
        "    return out.squeeze().cpu().numpy()[..., :-50] # weird pulse at the end of the model, need to be fixed later"
      ],
      "metadata": {
        "id": "2x5kVb3nc_eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synthesize speech"
      ],
      "metadata": {
        "id": "O159JnwCc6CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Maltby and Company would issue warrants on them deliverable to the importer, and the goods were then passed to be stored in neighboring warehouses.\n",
        "'''"
      ],
      "metadata": {
        "id": "ThciXQ6rc9Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a random reference in the training set, note that it doesn't matter which one you use\n",
        "path = \"Data/wavs/LJ001-0110.wav\"\n",
        "# this style vector ref_s can be saved as a parameter together with the model weights\n",
        "ref_s = compute_style(path)"
      ],
      "metadata": {
        "id": "jldPkJyCc83a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "wav = inference(text, ref_s, alpha=0.9, beta=0.9, diffusion_steps=10, embedding_scale=1)\n",
        "rtf = (time.time() - start) / (len(wav) / 24000)\n",
        "print(f\"RTF = {rtf:5f}\")\n",
        "import IPython.display as ipd\n",
        "display(ipd.Audio(wav, rate=24000, normalize=False))"
      ],
      "metadata": {
        "id": "_mIU0jqDdQ-c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}